{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b387b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e962aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfidenceWeightedVoting():\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def forward(self, instance_logits):\n",
    "        # get probabilities\n",
    "        instance_probs = torch.softmax(instance_logits, dim=-1)\n",
    "\n",
    "        # get predictions and confidences\n",
    "        instance_predictions = torch.argmax(instance_probs, dim=-1)\n",
    "        instance_confidences = torch.max(instance_probs, dim=-1)[0]\n",
    "\n",
    "        # use majority voting for each prediction weighted by confidence\n",
    "        bag_logits = torch.zeros(self.n_classes, device=instance_logits.device)\n",
    "        for pred, conf in zip(instance_predictions, instance_confidences):\n",
    "            bag_logits[pred] += conf\n",
    "\n",
    "        instance_info = {\n",
    "            \"predictions\": instance_predictions,\n",
    "            \"confidences\": instance_confidences,\n",
    "            \"probabilities\": instance_probs,\n",
    "        }\n",
    "\n",
    "        return bag_logits, instance_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470330ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIL_FabricClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained_path=None, agg_type='confidence_voting'):\n",
    "        super().__init__()\n",
    "\n",
    "        # load pretrained resnet18 model\n",
    "        self.instance_model = models.resnet18(pretrained=False)\n",
    "        checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
    "        self.instance_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        # replace final classifier to outut 7 classes\n",
    "        self.instance_model.fc = nn.Linear(512, n_classes)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.agg_type = agg_type\n",
    "        if agg_type == 'confidence_voting':\n",
    "            self.agg = ConfidenceWeightedVoting(n_classes)\n",
    "\n",
    "    def forward(self, bag_dict):\n",
    "        bag_logits_list = []\n",
    "        bag_pred_list = []\n",
    "        bag_info_dict = {}\n",
    "        bag_ids = []\n",
    "\n",
    "        for bag_id, instances in bag_dict.items():\n",
    "            instance_logits = self.instance_model(instances.float())\n",
    "\n",
    "            # MIL aggregation\n",
    "            bag_logits, instance_info = self.agg(instance_logits)\n",
    "\n",
    "            bag_prediction = torch.argmax(bag_logits)\n",
    "\n",
    "            bag_output_list.append(votes)\n",
    "            bag_ids.append(bag_id)\n",
    "\n",
    "            bag_logits_list.append(bag_logits)\n",
    "            bag_pred_list.append(bag_prediction)\n",
    "            bag_ids.append(bag_id)\n",
    "\n",
    "            bag_info_dict[bag_id] = {\n",
    "                'instance_predictions': instance_info['predictions'].cpu(),\n",
    "                'instance_confidences': instance_info['confidences'].cpu(),\n",
    "                'instance_probabilities': instance_info['probabilities'].cpu()\n",
    "            }\n",
    "\n",
    "        bag_logits_batch = torch.stack(bag_logits_list)\n",
    "        bag_pred_batch = torch.stack(bag_pred_list)\n",
    "\n",
    "        return bag_logits_batch, bag_pred_batch, bag_info_dict, bag_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05477a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FabricMILDataset(Dataset):\n",
    "    def __init__(self, data_dict, transform=None):\n",
    "        self.data_dict = data_dict\n",
    "        self.item_ids = list(data_dict.keys())\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.item_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item_id = self.item_ids[idx]\n",
    "        item_data = self.data_dict[item_id]\n",
    "        \n",
    "        image_paths = item_data['images']\n",
    "        label = item_data['label']\n",
    "        \n",
    "        # load all images for the bag\n",
    "        instances = []\n",
    "        for img_path in image_paths:\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                instances.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "        \n",
    "        # handle empty bags\n",
    "        if len(instances) == 0:\n",
    "            instances = [torch.zeros(3, 224, 224)]\n",
    "        \n",
    "        instances = torch.stack(instances)\n",
    "        return item_id, instances, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# custom collate function for dataset\n",
    "def collate_mil_bags(batch):\n",
    "    bag_ids, instances, labels = zip(*batch)\n",
    "    bag_dict = {bid: inst for bid, inst in zip(bag_ids, instances)}\n",
    "    labels = torch.stack(labels)\n",
    "    return bag_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70842db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, reg_factor=0.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    class_predictions = {}\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=\"training\")\n",
    "\n",
    "    for batch_idx, (bag_dict, labels) in enumerate(pbar):\n",
    "        bag_dict = {k: v.to(device) for k, v in bag_dict.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _, _, _ = model(bag_dict)\n",
    "        loss = criterion(logits, labels)\n",
    "        if reg_factor > 0:\n",
    "            reg = 0\n",
    "            for p in model.parameters():\n",
    "                reg += torch.norm(p, 2)\n",
    "            loss += reg_factor * reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        for p in preds.cpu().numpy():\n",
    "            class_predictions[p] = class_predictions.get(p, 0) + 1\n",
    "\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "        all_probs.extend(probs.cpu().tolist())\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{running_loss/(batch_idx+1):.4f}\",\n",
    "            \"acc\": f\"{100 * correct / total:.2f}%\"\n",
    "        })\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    print(f\"  class predictions: {dict(sorted(class_predictions.items()))}\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels, np.array(all_probs)\n",
    "\n",
    "def test(model, dataloader, criterion, device, return_details=False):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_bag_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bag_dict, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            bag_dict = {k: v.to(device) for k, v in bag_dict.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits, _, _, bag_ids = model(bag_dict)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            preds = probs.argmax(dim=1)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "            all_probs.extend(probs.cpu().tolist())\n",
    "            all_bag_ids.extend(bag_ids)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    if return_details:\n",
    "        return (\n",
    "            epoch_loss,\n",
    "            epoch_acc,\n",
    "            all_preds,\n",
    "            all_labels,\n",
    "            np.array(all_probs),\n",
    "            all_bag_ids\n",
    "        )\n",
    "    else:\n",
    "        return epoch_loss, epoch_acc, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, pred_labels, probas, num_classes):\n",
    "    true_labels = np.array(true_labels)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    f1 = f1_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(true_labels, probas, multi_class='ovo', average='macro')\n",
    "    except Exception:\n",
    "        auc_macro = np.nan\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(true_labels, pred_labels, labels=list(range(num_classes)))\n",
    "\n",
    "    # per-class metrics\n",
    "    TP = np.diag(cm).astype(float)\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "\n",
    "    FPR = np.where((FP + TN) > 0, FP / (FP + TN), 0.0)\n",
    "    FNR = np.where((FN + TP) > 0, FN / (FN + TP), 0.0)\n",
    "    TNR = np.where((TN + FP) > 0, TN / (TN + FP), 0.0)\n",
    "    TPR = np.where((TP + FN) > 0, TP / (TP + FN), 0.0)\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision_macro': float(precision),\n",
    "        'recall_macro': float(recall),\n",
    "        'f1_macro': float(f1),\n",
    "        'auc_macro': float(auc_macro),\n",
    "\n",
    "        'FPR_per_class': FPR.tolist(),\n",
    "        'FNR_per_class': FNR.tolist(),\n",
    "        'TPR_per_class': TPR.tolist(),\n",
    "        'TNR_per_class': TNR.tolist(),\n",
    "\n",
    "        'FPR_macro': float(np.mean(FPR)),\n",
    "        'FNR_macro': float(np.mean(FNR)),\n",
    "        'TPR_macro': float(np.mean(TPR)),\n",
    "        'TNR_macro': float(np.mean(TNR)),\n",
    "\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, phase=\"Metrics\"):\n",
    "    print(f\"\\n===== {phase} =====\")\n",
    "    print(f\"Accuracy:       {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision (mac):{metrics['precision_macro']:.4f}\")\n",
    "    print(f\"Recall (mac):   {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"F1 (mac):       {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"AUC (mac):      {metrics['auc_macro']:.4f}\")\n",
    "    print(f\"FPR (mac):      {metrics['FPR_macro']:.4f}\")\n",
    "    print(f\"FNR (mac):      {metrics['FNR_macro']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa658af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pad_to_square(img, fill=(255, 255, 255)):\n",
    "    w, h = img.size\n",
    "    if w == h:\n",
    "        return img\n",
    "    diff = abs(h - w)\n",
    "    if w < h:\n",
    "        padding = (diff // 2, 0, diff - diff // 2, 0)\n",
    "    else:\n",
    "        padding = (0, diff // 2, 0, diff - diff // 2)\n",
    "    return transforms.functional.pad(img, padding, fill=fill)\n",
    "\n",
    "def train_mil_fabric_kfold(\n",
    "    data_dict,\n",
    "    pretrained_checkpoint_path,\n",
    "    num_classes,\n",
    "    save_dir='mil_fabric_experiments',\n",
    "    n_folds=5,\n",
    "    n_epochs=15,\n",
    "    batch_size=4,\n",
    "    lr=0.0001,\n",
    "    reg_factor=0.0,\n",
    "    agg_type='confidence_voting'\n",
    "):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # calculate class distribution\n",
    "    all_labels = [data_dict[item_id]['label'] for item_id in data_dict.keys()]\n",
    "    unique_labels, label_counts = np.unique(all_labels, return_counts=True)\n",
    "    \n",
    "    print(f\"\\n Class Distribution:\")\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        print(f\"  Class {label}: {count} items ({count/len(all_labels)*100:.1f}%)\")\n",
    "    \n",
    "    class_weights = torch.FloatTensor([(len(all_labels) / (num_classes * count))**2\n",
    "                                          for count in label_counts])\n",
    "\n",
    "    # beta = 0.5\n",
    "    # class_weights = 1.0 / (label_counts ** beta)\n",
    "    # class_weights /= class_weights.sum() / len(label_counts)\n",
    "    # class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    class_weights = class_weights.to(device)\n",
    "\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        pad_to_square,  \n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        pad_to_square,  \n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    item_ids = list(data_dict.keys())\n",
    "    stratify_labels = [data_dict[item_id]['label'] for item_id in item_ids]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_results = []\n",
    "    all_predictions = {}\n",
    "\n",
    "    for fold, (trainval_idx, test_idx) in enumerate(skf.split(data_dict, stratify_labels)):\n",
    "        trainval_labels = [stratify_labels[i] for i in trainval_idx]\n",
    "        train_idx, val_idx = train_test_split(trainval_idx, test_size=0.10, stratify=trainval_labels, random_state=42)\n",
    "\n",
    "        train_items = {item_ids[i]: data_dict[item_ids[i]] for i in train_idx}\n",
    "        val_items = {item_ids[i]: data_dict[item_ids[i]] for i in val_idx}\n",
    "        test_items = {item_ids[i]: data_dict[item_ids[i]] for i in test_idx}\n",
    "\n",
    "        print(f\"Train bags: {len(train_items)}, Val bags: {len(val_items)}, Test bags: {len(test_items)}\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = FabricMILDataset(train_items, train_transform)\n",
    "        val_dataset = FabricMILDataset(val_items, val_transform)\n",
    "        test_dataset = FabricMILDataset(test_items, val_transform)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            collate_fn=collate_mil_bags,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            collate_fn=collate_mil_bags,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            collate_fn=collate_mil_bags,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # initialize model\n",
    "        model = MIL_FabricClassifier(\n",
    "            n_classes=num_classes,\n",
    "            pretrained_path=pretrained_checkpoint_path,\n",
    "            agg_type=agg_type\n",
    "        ).to(device)\n",
    "        \n",
    "        # optimizer and loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
    "        )\n",
    "        \n",
    "        # training loop\n",
    "        best_val_acc = 0.0\n",
    "        fold_history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': []\n",
    "        }\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{n_epochs}\")\n",
    "            \n",
    "            # TRAIN\n",
    "            train_loss, train_acc, train_preds, train_labels, train_probs = train_epoch(\n",
    "                model, train_loader, criterion, optimizer, device, reg_factor\n",
    "            )\n",
    "\n",
    "            # VAL\n",
    "            val_loss, val_acc, val_preds, val_labels, val_probs, val_bag_ids = validate(\n",
    "                model, val_loader, criterion, device, return_details=True\n",
    "            )\n",
    "            \n",
    "            # compute train + val metrics (per epoch)\n",
    "            train_metrics = calculate_metrics(\n",
    "                true_labels=train_labels,\n",
    "                pred_labels=train_preds,\n",
    "                probas=train_probs,\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "\n",
    "            val_metrics = calculate_metrics(\n",
    "                true_labels=val_labels,\n",
    "                pred_labels=val_preds,\n",
    "                probas=val_probs,\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            \n",
    "            fold_history['train_loss'].append(train_loss)\n",
    "            fold_history['train_acc'].append(train_acc)\n",
    "            fold_history['val_loss'].append(val_loss)\n",
    "            fold_history['val_acc'].append(val_acc)\n",
    "            \n",
    "            print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}%\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
    "            \n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            # save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'fold': fold,\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                }, save_path / f'best_model_fold{fold}.pth')\n",
    "                print(f\"  ✓ Saved best model (acc: {val_acc*100:.2f}%)\")\n",
    "        \n",
    "        fold_history.setdefault('train_metrics', []).append(train_metrics)\n",
    "        fold_history.setdefault('val_metrics', []).append(val_metrics)\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'history': fold_history\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Best Val Acc: {best_val_acc*100:.2f}%\")\n",
    "    \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Testing best model from fold {fold+1}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # load best model\n",
    "        checkpoint = torch.load(save_path / f'best_model_fold{fold}.pth')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # test\n",
    "        test_loss, test_acc, test_preds, test_labels, test_probs, test_bag_ids = validate(\n",
    "            model, test_loader, criterion, device, return_details=True\n",
    "        )\n",
    "        \n",
    "        test_metrics = calculate_metrics(test_labels, test_preds, test_probs, num_classes)\n",
    "        print_metrics(test_metrics, phase=\"Test\")\n",
    "\n",
    "        fold_results.append({\n",
    "            'test_metrics': test_metrics,\n",
    "        })\n",
    "\n",
    "        fold_predictions = {\n",
    "            'bag_id': test_bag_ids,\n",
    "            'true_label': test_labels,\n",
    "            'predicted_label': test_preds,\n",
    "            'probabilities': test_probs.tolist()\n",
    "        }\n",
    "        \n",
    "        fold_pred_df = pd.DataFrame({\n",
    "            'bag_id': test_bag_ids,\n",
    "            'true_label': test_labels,\n",
    "            'predicted_label': test_preds,\n",
    "            **{f'prob_class_{i}': test_probs[:, i] for i in range(num_classes)}\n",
    "        })\n",
    "        fold_pred_df.to_csv(save_path / f'predictions_fold{fold}.csv', index=False)\n",
    "        \n",
    "        for bag_id, true_label, pred_label, prob in zip(test_bag_ids, test_labels, test_preds, test_probs):\n",
    "            all_predictions[bag_id] = {\n",
    "                'fold': int(fold),\n",
    "                'true_label': int(true_label),       \n",
    "                'predicted_label': int(pred_label),\n",
    "                'probabilities': [float(p) for p in prob]\n",
    "            }\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'test_metrics': test_metrics,\n",
    "            'history': fold_history,\n",
    "            'predictions': fold_predictions\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} - Val Acc: {best_val_acc*100:.2f}%, Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"CROSS-VALIDATION SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    avg_acc = np.mean([r['best_val_acc'] for r in fold_results])\n",
    "    std_acc = np.std([r['best_val_acc'] for r in fold_results])\n",
    "    \n",
    "    print(f\"\\nAverage Validation Accuracy: {avg_acc*100:.2f}% ± {std_acc*100:.2f}%\")\n",
    "    print(f\"\\nPer-fold results:\")\n",
    "    for i, result in enumerate(fold_results):\n",
    "        print(f\"  Fold {i+1}: {result['best_val_acc']*100:.2f}%\")\n",
    "    \n",
    "    results_summary = {\n",
    "        'fold_results': [{\n",
    "            'fold': r['fold'],\n",
    "            'best_val_acc': float(r['best_val_acc']),\n",
    "            'history': {k: [float(x) for x in v] for k, v in r['history'].items()}\n",
    "        } for r in fold_results],\n",
    "        'avg_acc': float(avg_acc),\n",
    "        'std_acc': float(std_acc),\n",
    "        'config': {\n",
    "            'n_folds': n_folds,\n",
    "            'n_epochs': n_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'lr': lr,\n",
    "            'reg_factor': reg_factor,\n",
    "            'agg_type': agg_type,\n",
    "            'num_classes': num_classes\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(save_path / 'cv_results.json', 'w') as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Results saved to {save_path}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b989f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_dict_from_csv(csv_path, images_folder):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # create label mapping\n",
    "    unique_labels = sorted(df['label'].unique())\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    reverse_mapping = {idx: label for label, idx in label_mapping.items()}\n",
    "    \n",
    "    print(f\"Found {len(unique_labels)} fabric classes:\")\n",
    "    for label, idx in label_mapping.items():\n",
    "        print(f\"  {idx}: {label}\")\n",
    "    \n",
    "    images_path = Path(images_folder)\n",
    "    \n",
    "    data_dict = {}\n",
    "    missing_images = []\n",
    "    \n",
    "    for item_id, group in df.groupby('item_id'):\n",
    "        image_paths = []\n",
    "        for image_id in group['image_id']:\n",
    "            img_path = images_path / f\"{image_id}.jpg\"\n",
    "            if img_path.exists():\n",
    "                image_paths.append(str(img_path))\n",
    "            else:\n",
    "                missing_images.append(f\"{image_id}.jpg\")\n",
    "        \n",
    "        # skip items with no valid images\n",
    "        if len(image_paths) == 0:\n",
    "            print(f\"Warning: Item {item_id} has no valid images, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # get label\n",
    "        label_name = group['label'].iloc[0]\n",
    "        label_idx = label_mapping[label_name]\n",
    "        \n",
    "        data_dict[f'item_{item_id}'] = {\n",
    "            'images': image_paths,\n",
    "            'label': label_idx\n",
    "        }\n",
    "    \n",
    "    if missing_images:\n",
    "        print(f\"\\ {len(missing_images)} images not found in {images_folder}\")\n",
    "        print(f\"Missing: {missing_images[:5]}\")\n",
    "    \n",
    "    print(f\"\\nCreated data dictionary with {len(data_dict)} items\")\n",
    "    if len(data_dict) > 0:\n",
    "        example_key = list(data_dict.keys())[0]\n",
    "        print(f\"Example item: {example_key}\")\n",
    "        print(f\"  - Images: {len(data_dict[example_key]['images'])}\")\n",
    "        print(f\"  - Label: {data_dict[example_key]['label']} ({reverse_mapping[data_dict[example_key]['label']]})\")\n",
    "    \n",
    "    return data_dict, label_mapping, reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afd8a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 fabric classes:\n",
      "  0: Acrylic\n",
      "  1: Cotton\n",
      "  2: Linen\n",
      "  3: Nylon\n",
      "  4: Polyester\n",
      "  5: Suede\n",
      "  6: Viscose\n",
      "\n",
      "Created data dictionary with 2145 items\n",
      "Example item: item_1\n",
      "  - Images: 6\n",
      "  - Label: 0 (Acrylic)\n",
      "{'images': ['D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\1.jpg', 'D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\2.jpg', 'D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\3.jpg', 'D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\4.jpg', 'D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\5.jpg', 'D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\\\\6.jpg'], 'label': 0}\n",
      "{'Acrylic': 0, 'Cotton': 1, 'Linen': 2, 'Nylon': 3, 'Polyester': 4, 'Suede': 5, 'Viscose': 6}\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_data.csv\"\n",
    "images_folder = \"D:\\\\csci_461_textiles_project\\\\data\\\\fiber\\\\fiber_images\"\n",
    "data_dict, label_mapping, reverse_mapping = create_data_dict_from_csv(csv_path, images_folder)\n",
    "\n",
    "print(data_dict.get('item_1'))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f25a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 200, 2: 200, 5: 154, 6: 101, 3: 88, 4: 61, 0: 22})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# target maximum per class\n",
    "max_per_class = {\n",
    "    1: 200,  # downsample class 1\n",
    "    2: 200,  # downsample class 2\n",
    "}\n",
    "\n",
    "# group items by label\n",
    "by_class = {}\n",
    "for k, v in data_dict.items():\n",
    "    lbl = v[\"label\"]\n",
    "    by_class.setdefault(lbl, []).append((k, v))\n",
    "\n",
    "# downsample large classes\n",
    "balanced_items = []\n",
    "for lbl, items in by_class.items():\n",
    "    if lbl in max_per_class and len(items) > max_per_class[lbl]:\n",
    "        items = random.sample(items, max_per_class[lbl])\n",
    "    balanced_items.extend(items)\n",
    "\n",
    "# reconstruct new data_dict\n",
    "balanced_data_dict = {k: v for k, v in balanced_items}\n",
    "\n",
    "# check new distribution\n",
    "from collections import Counter\n",
    "print(Counter(v[\"label\"] for v in balanced_data_dict.values()))\n",
    "data_dict = balanced_data_dict\n",
    "len(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    # Train with 5-fold CV\n",
    "    results = train_mil_fabric_kfold(\n",
    "        data_dict=data_dict,\n",
    "        pretrained_checkpoint_path='D:\\\\csci_461_textiles_project\\\\res18_ckpt.pth',\n",
    "        num_classes=7,  # Adjust based on your fabric classes\n",
    "        save_dir='D:\\\\csci_461_textiles_project\\\\fiber_resnet_test_three',\n",
    "        n_folds=5,\n",
    "        n_epochs=30,\n",
    "        batch_size=8,\n",
    "        lr=0.00001,\n",
    "        agg_type='confidence_voting'  # or 'softmax_mean', 'noisy_and'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f492dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
